# Copyright 2024-2025 Ryan Nicholl, rnicholl@protonmail.com
# Generated by ChatGPT/Junie. Prompts authored by Ryan P. Nicholl.

import os
import sys
import time

import re
import subprocess
import argparse
import difflib
from collections import defaultdict

def normalize_name(name):
    # Remove middle initials
    words = name.split()
    new_words = []
    for word in words:
        if len(word) == 1 or (len(word) == 2 and word.endswith('.')):
            continue  # Skip middle initials
        else:
            new_words.append(word)
    normalized = ' '.join(new_words)
    return normalized.lower()  # Lowercase for consistent comparison


def norm_path(p: str) -> str:
    """
    Normalize repo paths for consistent matching across git outputs:
    - strip leading './'
    - strip leading 'a/' or 'b/' from diff headers
    - collapse redundant separators and up-level refs
    - preserve relative path (no absolute conversion)
    """
    if p is None:
        return ''
    s = p.strip()
    if s.startswith('./'):
        s = s[2:]
    # strip a/ or b/ prefixes (git diff headers)
    if s.startswith('a/') or s.startswith('b/'):
        s = s[2:]
    # Normalize separators and dot segments
    s = os.path.normpath(s)
    # Keep '.' meaning current dir out; want plain relative
    if s == '.':
        s = ''
    return s

def get_file_authors(file_path, *, debug: bool = False, verbose: bool = False):
    debug = debug or (os.getenv('COPYRIGHT_DEBUG', '').lower() in ('1', 'true', 'yes'))
    """
    Collect authorship years from git history, but IGNORE commits that only
    modified copyright comment lines. This prevents trivial copyright-header
    tweaks from inflating the year ranges.
    Also properly follow file renames/moves by tracking historical path aliases.
    """
    # Normalize the input path for internal matching
    file_path_norm = norm_path(file_path)
    # Build a rename-aware commit list with per-commit relevant paths
    log_cmd = ['git', 'log', '--follow', '-M', '-C', '--name-status', '--pretty=format:%H|%an|%ae|%ad', '--date=format:%Y', '--', file_path]
    if debug:
        print(f"[DEBUG] git log cmd: {' '.join(log_cmd)}")
    log = subprocess.run(log_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    if log.returncode != 0:
        print(f"Error running git log on {file_path}: {log.stderr}")
        return {}

    # Parse the log into commits with matched paths and maintain an alias set
    commits = []
    alias_set = {file_path_norm}
    current = None
    next_alias_set = alias_set.copy()

    def flush_current():
        nonlocal current
        if current is not None:
            commits.append(current)
            current = None

    for raw in log.stdout.splitlines():
        if not raw:
            continue
        if '|' in raw and raw.split('|', 1)[0] and len(raw.split('|')) == 4:
            # New commit header
            # finalize previous
            flush_current()
            # Carry over alias set updated by the later (newer) commit into this older one
            alias_set = next_alias_set.copy()
            try:
                chash, name, email, year = raw.split('|')
            except ValueError:
                if debug:
                    print(f"[DEBUG] Unexpected git log header: {raw}")
                # start a minimal commit anyway
                chash = raw.strip()
                name = email = year = ''
            if debug:
                try:
                    cur_alias_sorted = ','.join(sorted(alias_set))
                except Exception:
                    cur_alias_sorted = str(alias_set)
                print(f"[DEBUG] Start commit {chash.strip()[:12]}: alias set carried in = [{cur_alias_sorted}]")
            current = {
                'hash': chash.strip(),
                'name': name.strip(),
                'email': email.strip(),
                'year': year.strip(),
                # Initialize with current alias set so we consider these paths even
                # if --name-status omitted the file due to path scoping quirks
                'paths': set(alias_set),
            }
        else:
            # name-status lines
            parts = raw.split('\t')
            if not parts:
                continue
            tag = parts[0]
            updated_alias = alias_set.copy()
            if tag.startswith('R') or tag.startswith('C'):
                if len(parts) >= 3:
                    raw_old = parts[1]
                    raw_new = parts[2]
                    oldp = norm_path(raw_old)
                    newp = norm_path(raw_new)
                    touches = (oldp in alias_set) or (newp in alias_set)
                    if touches and current is not None:
                        current['paths'].update({oldp, newp})
                    # When walking backwards, the older alias is 'oldp'
                    alias_changed = False
                    if newp in alias_set or oldp in alias_set:
                        updated_alias.discard(newp)
                        updated_alias.add(oldp)
                        alias_changed = True
                    if debug:
                        ch = (current.get('hash', '')[:12] if current else '')
                        print(f"[DEBUG] Detected {tag} rename/copy: {raw_old} -> {raw_new} | norm: {oldp} -> {newp} (touches_alias={touches}) commit={ch}")
                        if current is not None:
                            try:
                                cur_paths_sorted = ','.join(sorted(current['paths']))
                            except Exception:
                                cur_paths_sorted = str(current['paths'])
                            print(f"[DEBUG]   current relevant paths: [{cur_paths_sorted}]")
                        if alias_changed:
                            try:
                                next_alias_sorted = ','.join(sorted(updated_alias))
                            except Exception:
                                next_alias_sorted = str(updated_alias)
                            print(f"[DEBUG]   alias set for next (older) commit: [{next_alias_sorted}]")
            elif tag in ('M', 'A', 'D', 'T'):  # modified, added, deleted, type change
                if len(parts) >= 2:
                    p = norm_path(parts[1])
                    if p in alias_set and current is not None:
                        current['paths'].add(p)
                # alias set unchanged
            else:
                # Sometimes name-status may include just a path without a tag when
                # configured differently; handle defensively
                if len(parts) == 1:
                    p = norm_path(parts[0])
                    if p in alias_set and current is not None:
                        current['paths'].add(p)
            # stage the alias update for the next (older) commit header
            next_alias_set = updated_alias

    # flush last commit
    flush_current()

    if debug:
        print(f"[DEBUG] Alias tracking finished. Total commits scanned: {len(commits)}")

    def commit_has_substantive_changes(commit_hash: str, relevant_paths: set) -> bool:
        """
        Return True if the commit modifies the file (under any of its known
        paths for that commit) in a way other than comment-only/whitespace.
        """
        try:
            show_cmd = ['git', 'show', '-w', '--no-color', '--format=', '--unified=0', f'{commit_hash}']
            if debug:
                print(f"[DEBUG] git show cmd: {' '.join(show_cmd)}")
            diff = subprocess.run(show_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            if diff.returncode != 0:
                if debug:
                    print(f"[DEBUG] git show failed for {commit_hash}: {diff.stderr.strip()}")
                return True
        except Exception as e:
            if debug:
                print(f"[DEBUG] Exception running git show for {commit_hash}: {e}")
            return True

        # Normalize relevant paths for matching
        relevant_paths_norm = {norm_path(p) for p in (relevant_paths or set())}

        # Parse patch sections and collect changed lines only for matched file pairs
        changed_lines = []
        cur_a = cur_b = None
        consider_section = False

        for raw in diff.stdout.splitlines():
            if raw.startswith('diff --git '):
                # New section
                consider_section = False
                cur_a = cur_b = None
                try:
                    # format: diff --git a/path b/path
                    parts = raw.strip().split()
                    a_path = norm_path(parts[2]) if len(parts) > 2 else ''
                    b_path = norm_path(parts[3]) if len(parts) > 3 else ''
                    cur_a, cur_b = a_path, b_path
                    if (cur_a in relevant_paths_norm) or (cur_b in relevant_paths_norm):
                        consider_section = True
                except Exception:
                    consider_section = False
                continue
            if not consider_section:
                # skip lines until we enter a relevant section
                continue
            if raw.startswith('index ') or raw.startswith('similarity ') or raw.startswith('rename '):
                continue
            if raw.startswith('--- ') or raw.startswith('+++ '):
                # could be paths or /dev/null
                continue
            if raw.startswith('@@'):
                # hunk header
                continue
            if raw and (raw[0] == '+' or raw[0] == '-'):
                changed_lines.append(raw)

        if not changed_lines:
            if debug:
                rp = ','.join(sorted(relevant_paths_norm))
                print(f"[DEBUG] Commit {commit_hash[:12]} -> no content changes for [{rp}] (metadata-only/rename). Classified: TRIVIAL")
            return False

        # Patterns to detect trivial comment-only copyright/boilerplate edits
        comment_prefix_re = re.compile(r'^\s*(//|#|/\*+|\*/)\s*', re.IGNORECASE)
        copyright_kw_re = re.compile(r'\b(copyright|copr\.)\b|\(c\)', re.IGNORECASE)
        boiler_kw_re = re.compile(r'\b(spdx|license|licence|created by|generated by|prompts? authored by|original version by)\b', re.IGNORECASE)

        def is_trivial_comment(text: str) -> bool:
            s = text.lstrip('+-')
            if not s.strip():
                return True  # whitespace-only
            if comment_prefix_re.match(s):
                body = comment_prefix_re.sub('', s).strip()
                if not body:
                    return True
                if copyright_kw_re.search(body) or boiler_kw_re.search(body):
                    return True
            return False

        substantive = False
        reason = "all comment/whitespace"
        for cl in changed_lines:
            if not is_trivial_comment(cl):
                substantive = True
                reason = f"found substantive line: {cl[:80]}"
                break
        if debug:
            sample = '\n'.join(changed_lines[:5])
            rp = ','.join(sorted(relevant_paths))
            print(f"[DEBUG] Commit {commit_hash[:12]} on [{rp}]: {('SUBSTANTIVE' if substantive else 'TRIVIAL')} â€” {reason}\n[DEBUG] Sample diff lines:\n{sample}")
        return substantive

    # Accumulate authors over substantive commits
    authors = {}
    for c in commits:
        if not c or not c.get('hash'):
            continue
        # If name-status did not list a matching file for this commit, still try with current alias
        relevant_paths = c['paths'] if c['paths'] else {file_path}
        substantive = commit_has_substantive_changes(c['hash'], relevant_paths)
        if debug:
            print(f"[DEBUG] Commit {c['hash'][:12]} by {c.get('name','')} <{c.get('email','')}> in {c.get('year','')}: {'SUBSTANTIVE' if substantive else 'TRIVIAL'}")
        if not substantive:
            continue
        name = c.get('name', '').strip()
        email = c.get('email', '').strip()
        year = c.get('year', '').strip()
        if not (name and email and year):
            # Fallback: query author/year if missing
            if debug:
                print(f"[DEBUG] Missing author metadata for {c['hash'][:12]}, querying git show for author/year")
            meta = subprocess.run(['git', 'show', '-s', '--format=%an|%ae|%ad', '--date=format:%Y', c['hash']], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            if meta.returncode == 0:
                try:
                    name, email, year = meta.stdout.strip().split('|')
                except Exception:
                    pass
        normalized_name = normalize_name(name)
        key = (normalized_name, email.lower())
        if key not in authors:
            authors[key] = {'names': set(), 'years': set()}
        if name:
            authors[key]['names'].add(name)
        if year:
            authors[key]['years'].add(year)

    if verbose or debug:
        print(f"[INFO] Authors for {file_path} (post-filter):")
        for (norm, email), data in authors.items():
            print(f"  - {sorted(data['names'])[-1] if data['names'] else norm} <{email}> years={sorted(data['years'])}")
    return authors

def format_years(years_set):
    years = sorted(int(year) for year in years_set)
    ranges = []
    if not years:
        return ''
    start = years[0]
    end = years[0]
    for year in years[1:]:
        if year == end + 1:
            end = year
        else:
            if start == end:
                ranges.append(f"{start}")
            else:
                ranges.append(f"{start}-{end}")
            start = end = year
    if start == end:
        ranges.append(f"{start}")
    else:
        ranges.append(f"{start}-{end}")
    return ', '.join(ranges)

def parse_existing_copyrights(lines):
    pattern = re.compile(r'''
        ^\s*
        (?P<comment_marker>//|\#|\*)
        \s*
        Copyright
        (\s*\(c\))?
        \s+
        (?P<years>[\d,\-,\s]+)
        \s+
        (?P<name>[\w\s\.\-]+?)
        [,\s]*
        [<\(\[]?
        (?P<email>[\w\.\+\-]+@[\w\.\-]+)
        [>\)\]]?
        .*$
        ''', re.IGNORECASE | re.VERBOSE)
    in_copyright_block = False
    copyright_comments = []
    license_text = []
    code_starts_at = None
    for i, line in enumerate(lines):
        if re.match(r'^\s*$', line):
            continue  # Skip empty lines
        comment_line = re.match(r'^\s*(//|\#|\*|\/*)', line)
        if comment_line:
            match = pattern.match(line)
            if match:
                in_copyright_block = True
                data = match.groupdict()
                years = set(re.findall(r'\d{4}', data['years']))
                name = data['name'].strip()
                email = data['email'].strip()
                comment_marker = data['comment_marker']
                copyright_comments.append({
                    'line_num': i,
                    'line': line,
                    'years': years,
                    'name': name,
                    'email': email,
                    'comment_marker': comment_marker
                })
            elif in_copyright_block:
                license_text.append((i, line))
            else:
                continue  # Comment outside of copyright block
        else:
            if in_copyright_block:
                code_starts_at = i
                break
    return copyright_comments, license_text, code_starts_at

def remove_created_by_comments(lines):
    """
    Remove only boilerplate "Created by"/"Generated by"-style single-line comments,
    and optionally adjacent empty comment-only lines. Preserve all other content.
    """
    indices_to_delete = set()

    # Patterns:
    #  - comment prefix (//, #, *, /*) possibly with extra *s
    comment_prefix_re = re.compile(r"^\s*(//|#|\*|/\*+)\s*")
    #  - empty comment line (only the comment marker and optional whitespace)
    empty_comment_re = re.compile(r"^\s*(//|#|\*|/\*+/?|\*/)?\s*$")
    #  - target phrases we want to remove
    target_phrase_re = re.compile(r"\b(Created by|Generated by|Prompts? authored by|Original version by)\b", re.IGNORECASE)

    for i, line in enumerate(lines):
        m = comment_prefix_re.match(line)
        if not m:
            continue
        # Strip the prefix to inspect the comment text
        text = line[m.end():].strip()
        if not target_phrase_re.search(text):
            continue
        # Mark this line for deletion
        indices_to_delete.add(i)
        # If the previous line is an empty comment-only line, remove it too
        if i > 0 and empty_comment_re.match(lines[i-1]):
            indices_to_delete.add(i-1)
        # If the next line is an empty comment-only line, remove it too
        if i + 1 < len(lines) and empty_comment_re.match(lines[i+1]):
            indices_to_delete.add(i+1)

    # Rebuild the lines, skipping those marked for deletion
    new_lines = [line for idx, line in enumerate(lines) if idx not in indices_to_delete]
    return new_lines

def detect_comment_marker(file_path):
    ext = os.path.splitext(file_path)[1]
    if ext in ['.py', '.sh', '.pl']:
        return '#'
    elif ext in ['.cpp', '.hpp', '.c', '.h', '.java', '.js']:
        return '//'
    else:
        return '#'

def update_file(file_path, *, debug: bool = False, verbose: bool = False, dry_run: bool = False):
    if debug:
        print(f"[DEBUG] update_file: path={file_path} debug={debug} verbose={verbose} dry_run={dry_run}")
    authors = get_file_authors(file_path, debug=debug, verbose=verbose)
    if not authors:
        if verbose or debug:
            print(f"[INFO] No substantive git history for {file_path} (after filtering)")
        return

    with open(file_path, 'r') as f:
        lines = f.readlines()
    original_lines = list(lines)
    lines = remove_created_by_comments(lines)
    if debug and original_lines != lines:
        print(f"[DEBUG] remove_created_by_comments modified {file_path} (in-memory)")

    # Parse existing copyrights
    c_comments, license_text, code_starts_at = parse_existing_copyrights(lines)

    # Build a mapping from (normalized_name, email) to existing comments
    existing_authors = {}
    for c in c_comments:
        normalized_name = normalize_name(c['name'])
        key = (normalized_name.lower(), c['email'].lower())
        existing_authors[key] = c

    # Update existing comments and prepare to add new ones
    updated_lines = lines.copy()

    for author_key, author_data in sorted(authors.items(), key=lambda kv: sorted(kv[1]['years'])):
        normalized_name, email = author_key
        years = author_data['years']
        names = author_data['names']
        # Choose the name with the most characters (i.e., the one with middle initial)
        name = max(names, key=len)
        key = (normalized_name.lower(), email.lower())
        if key in existing_authors:
            c = existing_authors[key]
            all_years = c['years'].union(years)
            formatted_years = format_years(all_years)
            new_line = f"{c['comment_marker']} Copyright {formatted_years} {name}, {email}\n"
            if debug:
                print(f"[DEBUG] Updating header line {c['line_num']} for {name} <{email}> to years: {formatted_years}")
            updated_lines[c['line_num']] = new_line
        else:
            # Need to add a new comment
            formatted_years = format_years(years)
            if c_comments:
                # Add after license text
                insert_pos = (license_text[-1][0] + 1) if license_text else (c_comments[-1]['line_num'] + 1)
            else:
                # Add at the top
                insert_pos = 0
            comment_marker = detect_comment_marker(file_path)
            new_comment = f"{comment_marker} Copyright {formatted_years} {name}, {email}\n"
            if debug:
                print(f"[DEBUG] Inserting new header at {insert_pos} for {name} <{email}> years: {formatted_years}")
            updated_lines.insert(insert_pos, new_comment)
            # Adjust the line numbers of subsequent lines
            for c in c_comments:
                if c['line_num'] >= insert_pos:
                    c['line_num'] += 1

    if dry_run:
        if verbose or debug:
            print(f"[DRY-RUN] Planned changes for {file_path}:")
        diff = difflib.unified_diff(
            original_lines,
            updated_lines,
            fromfile=f"a/{file_path}",
            tofile=f"b/{file_path}",
            lineterm=''
        )
        for line in diff:
            print(line)
        return

    with open(file_path, 'w') as f:
        f.writelines(updated_lines)

def main():
    parser = argparse.ArgumentParser(description='Update copyright comments')
    parser.add_argument('paths', nargs='*', help='Files or directories to process')
    parser.add_argument('--debug', action='store_true', help='Enable debug logging')
    parser.add_argument('--verbose', '-v', action='store_true', help='Enable verbose logging')
    parser.add_argument('--dry-run', action='store_true', help='Show planned changes, do not write files')
    args = parser.parse_args()

    debug = args.debug or (os.getenv('COPYRIGHT_DEBUG', '').lower() in ('1', 'true', 'yes'))

    # Specify the file extensions you want to process
    extensions = ('.hpp', '.cpp', '.py', '.c', '.h', '.java', '.js')

    files_to_process = []

    if args.paths:
        for path in args.paths:
            if os.path.isfile(path):
                if path.endswith(extensions):
                    files_to_process.append(path)
            elif os.path.isdir(path):
                for root, dirs, files in os.walk(path):
                    for file in files:
                        if file.endswith(extensions):
                            files_to_process.append(os.path.join(root, file))
    else:
        # If no paths are provided, process all files tracked by git
        cmd = ['git', 'ls-files']
        if debug:
            print(f"[DEBUG] git ls-files cmd: {' '.join(cmd)}")
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        if result.returncode != 0:
            print(f"Error running git ls-files: {result.stderr}")
            return
        files = result.stdout.strip().split('\n')
        for file_path in files:
            if file_path.endswith(extensions):
                files_to_process.append(file_path)

    for file_path in files_to_process:
        if args.verbose or debug:
            print(f"Processing {file_path}")
        update_file(file_path, debug=debug, verbose=args.verbose, dry_run=args.dry_run)

if __name__ == '__main__':
    main()
